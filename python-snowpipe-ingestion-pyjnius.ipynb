{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7196f217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import version as v\n",
    "import json \n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "date_format_str = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "import jnius_config\n",
    "import phonenumbers" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3b8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = pd.to_datetime(datetime.now(), format=date_format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dacbc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the Snowpipe Streaming JAVA SDK Files to classpath\n",
    "jnius_config.set_classpath(os.getcwd(),'snowflake-ingest-sdk-1.1.0.jar')\n",
    "jnius_config.add_classpath(os.getcwd(),'slf4j-api-1.7.21.jar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa50d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jnius import autoclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0edafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "InsertValidationResponse_class = autoclass(\"net.snowflake.ingest.streaming.InsertValidationResponse\")\n",
    "OpenChannelRequest_class = autoclass(\"net.snowflake.ingest.streaming.OpenChannelRequest\")\n",
    "SnowflakeStreamingIngestChannel_class = autoclass(\"net.snowflake.ingest.streaming.SnowflakeStreamingIngestChannel\")\n",
    "SnowflakeStreamingIngestClient_class = autoclass(\"net.snowflake.ingest.streaming.SnowflakeStreamingIngestClient\")\n",
    "OpenChannelRequestBuilder_class = autoclass(\"net.snowflake.ingest.streaming.OpenChannelRequest$OpenChannelRequestBuilder\")\n",
    "OnErrorOption_class = autoclass(\"net.snowflake.ingest.streaming.OpenChannelRequest$OnErrorOption\")\n",
    "SnowflakeStreamingIngestClientFactory_class = autoclass(\"net.snowflake.ingest.streaming.SnowflakeStreamingIngestClientFactory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447aa2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jnius.reflect.net.snowflake.ingest.streaming.OpenChannelRequest'>\n"
     ]
    }
   ],
   "source": [
    "print(OpenChannelRequest_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194064d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Properties_class = autoclass(\"java.util.Properties\")\n",
    "FileInputStream_class = autoclass(\"java.io.FileInputStream\")\n",
    "InputStream_class = autoclass(\"java.io.InputStream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70bf0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Snowflake credentials from config file\n",
    "with open('snowflake_env_login_creds.json') as f:\n",
    "    data = json.load(f)\n",
    "#Fetch Snowflake Database credentials    \n",
    "    USERNAME = data['user']\n",
    "    URL = data['url']\n",
    "    SF_ACCOUNT = data['account']\n",
    "    PRIVATE_KEY = data['private_key']\n",
    "    PORT = data['port']\n",
    "    HOST = data['host']\n",
    "    SCHEMA = data['schema']\n",
    "    SCHEME = data['scheme']\n",
    "    DATABASE = data['database']\n",
    "    TABLE = data['table']\n",
    "    CONNECTION_STRING = data['connection_string']\n",
    "    ROLE = data['role']\n",
    "    WAREHOUSE = data['warehouse']\n",
    "#Fetch MYSQL Database credentials    \n",
    "    MYSQL_URL = data['mysql_url']\n",
    "    MYSQL_USERNAME = data['mysql_user']\n",
    "    MYSQL_PWD = data['mysql_pwd']\n",
    "    MYSQL_DATABASE = data['mysql_database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c95243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/dk27gmpd3nvdfd1pgz918l580000gn/T/ipykernel_18941/1509798917.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_dataFrame = pd.read_sql(query,mydb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ROW_INDEX          USER_ID FIRST_NAME LAST_NAME     SEX  \\\n",
      "0         1  e09c4f4cbfEFaFd       Dawn   Trevino    Male   \n",
      "1         2  D781D28b845Ab9D       Dale  Mcknight    Male   \n",
      "2         3  eda7EcaF87b2D80    Herbert      Bean  Female   \n",
      "3         4  E75ACea5D7AeC3e      Karen   Everett  Female   \n",
      "4         5  9C4Df1246ddf543     Angela      Shea    Male   \n",
      "\n",
      "                        EMAIL                  PHONE DATE_OF_BIRTH  \\\n",
      "0     clintongood@example.org           360-423-5286    1972-01-17   \n",
      "1  clairebradshaw@example.org             9062423229    1931-01-31   \n",
      "2    johnnybooker@example.org  001-149-154-0679x1617    2018-02-10   \n",
      "3           wkhan@example.org     870.294.7563x20939    1938-06-14   \n",
      "4  reginaldgarner@example.com           242.442.2978    1971-11-22   \n",
      "\n",
      "                       JOB_TITLE  \n",
      "0        Teacher, primary school  \n",
      "1  Development worker, community  \n",
      "2              Ceramics designer  \n",
      "3     Civil engineer, consulting  \n",
      "4      Health and safety adviser  \n"
     ]
    }
   ],
   "source": [
    "import mysql.connector as connection\n",
    "\n",
    "try:\n",
    "    mydb = connection.connect(host=MYSQL_URL, database=MYSQL_DATABASE,user=MYSQL_USERNAME, passwd=MYSQL_PWD,use_pure=True)\n",
    "    query = \"Select * from people_100k;\"\n",
    "    result_dataFrame = pd.read_sql(query,mydb)\n",
    "    print(result_dataFrame.head(5))\n",
    "    \n",
    "    mydb.close() #close the connection\n",
    "    \n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc44982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "log4j:WARN No appenders could be found for logger (io.netty.util.internal.logging.InternalLoggerFactory).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Streaming Channel Valid - True\n",
      "Is Streaming Ingest Channel Open - False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "#Populate connection string for streaming channel to snowflake    \n",
    "    props = Properties_class()\n",
    "    props.put(\"user\", USERNAME)\n",
    "    props.put(\"url\", URL)\n",
    "    props.put(\"account\", SF_ACCOUNT)\n",
    "    props.put(\"private_key\", PRIVATE_KEY)\n",
    "    props.put(\"port\", PORT)\n",
    "    props.put(\"host\", HOST)\n",
    "    props.put(\"schema\", SCHEMA)\n",
    "    props.put(\"scheme\", SCHEME)\n",
    "    props.put(\"database\", DATABASE)\n",
    "    props.put(\"table\", TABLE)\n",
    "    props.put(\"connect_string\", CONNECTION_STRING)\n",
    "    props.put(\"role\", ROLE)\n",
    "    props.put(\"warehouse\", WAREHOUSE)    \n",
    "    \n",
    "#Create a secure connection to snowflake   \n",
    "    client = SnowflakeStreamingIngestClientFactory_class.builder(\"CLIENT_FOR_SQLDWLOAD\").setProperties(props).build()\n",
    "\n",
    "#Create the streaming channel to snowflake    \n",
    "    request1 = OpenChannelRequest_class.builder(\"DWLOAD_CHANNEL\").setDBName(props.getProperty(\"database\")).setSchemaName(props.getProperty(\"schema\")).setTableName(props.getProperty(\"table\")).setOnErrorOption(OnErrorOption_class.CONTINUE).build()\n",
    "\n",
    "#Open a streaming ingest channel from the given client\n",
    "    channel1 = client.openChannel(request1)\n",
    "    print(\"Is Streaming Channel Valid - {}\".format(channel1.isValid()))\n",
    "    print(\"Is Streaming Ingest Channel Open - {}\".format(channel1.isClosed()))\n",
    "    #print(channel1.isClosed())\n",
    "    #print(channel1.isValid())    \n",
    "    \n",
    "except Exception as err:\n",
    "    print(f\"Exception: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd6f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "HashMap_class = autoclass(\"java.util.HashMap\")\n",
    "ArrayList_class = autoclass(\"java.util.ArrayList\")\n",
    "String_class = autoclass(\"java.lang.String\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec5ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bulk_rows = ArrayList_class()\n",
    "    \n",
    "    for index, row in result_dataFrame.iterrows():    \n",
    "        java_maprow = HashMap_class()\n",
    "        java_maprow.put(\"customer_id\",row[\"USER_ID\"])\n",
    "        java_maprow.put(\"email\",row[\"EMAIL\"])\n",
    "        java_maprow.put(\"phone\",row[\"PHONE\"])\n",
    "        java_maprow.put(\"date_of_birth\",row[\"DATE_OF_BIRTH\"])\n",
    "        bulk_rows.add(java_maprow)\n",
    "    \n",
    "\n",
    "except Exception as err:\n",
    "    print(f\"Exception: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b5f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bulk_rows[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c444d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_insert_start_time = pd.to_datetime(datetime.now(), format=date_format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a215c226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Closed = True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    if(channel1.isClosed()):\n",
    "        print(\"Channel is closed. Insert to Snowflake Table failed\")\n",
    "    else:\n",
    "        #response = channel1.insertRow(row, \"0\");\n",
    "        response = channel1.insertRows(bulk_rows, \"0\");\n",
    "\n",
    "        if(response.hasErrors()):\n",
    "            print(response.hasErrors())\n",
    "            print(response.toString())  #If there are errors then print to output            \n",
    "\n",
    "except Exception as err:\n",
    "    print(f\"Exception: {err}\") \n",
    "finally:\n",
    "    channel1.close().get() #Close channel to snowflake\n",
    "    print(\"Channel Closed = {}\".format(channel1.isClosed()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46153301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to ingest 500000 records in seconds:10.692488\n",
      "Total pipeline execution time in seconds:50.369858\n"
     ]
    }
   ],
   "source": [
    "end_time = pd.to_datetime(datetime.now(), format=date_format_str)\n",
    "# Get the interval between two datetimes as timedelta object\n",
    "ingest_diff = end_time - stream_insert_start_time\n",
    "pipeline_diff = end_time - start_time\n",
    "print('Total time to ingest {} records in seconds:{}'.format(len(result_dataFrame),ingest_diff.total_seconds()))\n",
    "print('Total pipeline execution time in seconds:{}'.format(pipeline_diff.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "722ce7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(channel1.isClosed())\n",
    "#print(channel1.isValid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2ce317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "offsetTokenFromSnowflake = channel1.getLatestCommittedOffsetToken()\n",
    "print(int(offsetTokenFromSnowflake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ca6a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Snowpark code to validate that records have been inserted into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2316411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13994451778\n",
      "0013994451778 ext. 8552\n"
     ]
    }
   ],
   "source": [
    "z = phonenumbers.parse(\"001-399-445-1778x8552\", \"US\")\n",
    "print(z.national_number)\n",
    "print(phonenumbers.format_number(z, phonenumbers.PhoneNumberFormat.to_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "239bd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(z.national_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2466b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Snowpark Connection\n",
    "# Specify connection parameters\n",
    "connection_parameters = {\n",
    "    \"account\": SF_ACCOUNT,\n",
    "    \"user\": USERNAME,\n",
    "    \"password\": MYSQL_PWD,\n",
    "    \"role\": ROLE,\n",
    "    \"warehouse\": WAREHOUSE,\n",
    "    \"database\": DATABASE,\n",
    "    \"schema\": SCHEMA,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eff23529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Snowpark session\n",
    "snowpark_session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4faa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpark_df = snowpark_session.table(\"SNOWPIPE_STREAMING.DEV.sf_customer_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94653111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in Customer RAW table - 500000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total records in Customer RAW table - {}\".format(snowpark_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5091f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package phonenumbers in the local environment is 8.13.11, which does not fit the criteria for the requirement phonenumbers. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "#Transform phone no. column and format DOB\n",
    "from snowflake.snowpark.functions import udf\n",
    "snowpark_session.add_packages(\"numpy\", \"pandas\", \"phonenumbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd34d513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.udf.UserDefinedFunction at 0x7fe5c5685c40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def parse_phone_no(x: str) -> str:\n",
    "    try:\n",
    "        return str(phonenumbers.parse(x,\"US\").national_number) \n",
    "    except Exception as err:\n",
    "        return \"0000000000\"     #setting a default value on error\n",
    "    \n",
    "##################################################################\n",
    "## Register UDF in Snowflake\n",
    "### Add packages and data types\n",
    "from snowflake.snowpark.types import IntegerType, StringType\n",
    "### Upload UDF to Snowflake\n",
    "snowpark_session.udf.register(\n",
    "    func = parse_phone_no\n",
    "  , return_type = StringType()\n",
    "  , input_types = [StringType()]\n",
    "  , is_permanent = True\n",
    "  , name = 'parse_phone_no'\n",
    "  , replace = True\n",
    "  , stage_location = '@UDF_STAGE'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "906cd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_start_time = pd.to_datetime(datetime.now(), format=date_format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ccd352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(number of rows inserted=500000)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowpark_session.sql('''\n",
    "                    insert into dev.sf_customer_gold\n",
    "                    (select customer_id,\n",
    "                        email,\n",
    "                        parse_phone_no(phone),\n",
    "                        to_date(date_of_birth)\n",
    "                        from dev.sf_customer_raw);''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56a68447",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpark_df = snowpark_session.table(\"SNOWPIPE_STREAMING.DEV.sf_customer_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0f369a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed GOLD table [sf_customer_gold] created. Total records - 500000\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed GOLD table [sf_customer_gold] created. Total records - {}\".format(snowpark_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6672a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transformation execution time in seconds:13.925515\n"
     ]
    }
   ],
   "source": [
    "tf_end_time = pd.to_datetime(datetime.now(), format=date_format_str)\n",
    "# Get the interval between two datetimes as timedelta object\n",
    "tf_diff = tf_end_time - tf_start_time\n",
    "print('Total transformation execution time in seconds:{}'.format(tf_diff.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2348cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
